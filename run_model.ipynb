{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.classifier import TransformerEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"hidden_size\": 96,  # size of the hidden layers and embeddings\n",
    "    \"hidden_ff\": 128,  # size of the position-wise feed-forward layer\n",
    "    \"n_encoders\": 4,  # number of encoder blocks\n",
    "    \"n_heads\": 8,  # number of attention heads in the multiheadattention module\n",
    "    \"n_local\": 2,  # number of local attention heads\n",
    "    \"local_window_size\": 4,  # size of the window for local attention\n",
    "    'batch_size': 12,\n",
    "    \"max_length\": 500,  # maximum length of the input sequence\n",
    "    \"vocab_size\": 1000,  # size of the vocabulary\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 30,\n",
    "    \"attention_type\": \"performer\",\n",
    "    \"norm_type\": \"rezero\",\n",
    "    \"num_random_features\": 32,  # number of random features for the Attention module (Performer uses this)\n",
    "    \"emb_dropout\": 0.1,  # dropout for the embedding block\n",
    "    \"fw_dropout\": 0.1,  # dropout for the position-wise feed-forward layer\n",
    "    \"att_dropout\": 0.1,  # dropout for the multiheadattention module\n",
    "    \"dc_dropout\": 0.1,  # dropout for the decoder block\n",
    "    \"hidden_act\": \"swish\",  # activation function for the hidden layers (attention layers use ReLU)\n",
    "    \"epsilon\": 1e-8,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "}\n",
    "model = TransformerEncoder(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hparams.batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    'tokens': torch.randint(0, model.hparams.vocab_size, (model.hparams.batch_size, model.hparams.max_length)),\n",
    "    'abspos': torch.arange(0, model.hparams.max_length).unsqueeze(0).repeat(model.hparams.batch_size, 1),\n",
    "    'age': torch.randint(0, 100, (model.hparams.batch_size, 1)),\n",
    "    'padding_mask': torch.zeros(model.hparams.batch_size, model.hparams.max_length),\n",
    "    'targets': torch.randint(0, 2, (model.hparams.batch_size, 1)).float(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': tensor([[-1.3514],\n",
       "         [-1.0725],\n",
       "         [-0.8076],\n",
       "         [-1.1908],\n",
       "         [-1.4738],\n",
       "         [-1.1028],\n",
       "         [-1.2330],\n",
       "         [-1.1628],\n",
       "         [-0.8098],\n",
       "         [-1.0998],\n",
       "         [-1.1409],\n",
       "         [-1.2202]], grad_fn=<AddmmBackward0>),\n",
       " 'preds': tensor([[0.2056],\n",
       "         [0.2549],\n",
       "         [0.3084],\n",
       "         [0.2331],\n",
       "         [0.1864],\n",
       "         [0.2492],\n",
       "         [0.2257],\n",
       "         [0.2382],\n",
       "         [0.3079],\n",
       "         [0.2498],\n",
       "         [0.2422],\n",
       "         [0.2279]], grad_fn=<SigmoidBackward0>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1722, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training_step(batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Metrics\n",
      "Train Metrics\n",
      "Loss: tensor(1.0116)\n",
      "Accuracy: tensor(0.3750)\n",
      "MCC: tensor(-0.1054)\n"
     ]
    }
   ],
   "source": [
    "model.on_train_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "life2vec-light-Ez8u7ZRp-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
